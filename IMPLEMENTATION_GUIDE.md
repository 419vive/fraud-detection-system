# ðŸš€ IEEE-CIS è©é¨™æª¢æ¸¬ - å…·é«”å¯¦ä½œæŒ‡å—

## ðŸ“‹ **å¯¦ä½œéšŽæ®µç¸½è¦½**

åŸºæ–¼æˆ‘å€‘çš„å°ˆæ¡ˆæž¶æ§‹ç¸½è¦½ [[memory:4324112]] å’Œå”ä½œæŒ‡å— [[memory:4324131]]ï¼Œä»¥ä¸‹æ˜¯å…·é«”çš„å¯¦ä½œæ­¥é©Ÿï¼š

---

## ðŸŒ **ç¬¬ä¸€æ­¥ï¼šç«‹å³é–‹å§‹é‹è¡Œ**

### âœ… **Jupyter Lab å·²é‹è¡Œ** 
```
ðŸ”— è¨ªå•é€£çµï¼šhttp://localhost:8888/lab?token=ae4342b358d3b76f1648e849bd8d47abeab0ed83cd1a0151
```

### ðŸ““ **é‹è¡Œæ•¸æ“šæŽ¢ç´¢ç­†è¨˜æœ¬**
1. åœ¨ç€è¦½å™¨ä¸­æ‰“é–‹ä¸Šè¿°é€£çµ
2. å°Žèˆªåˆ° `notebooks/01_data_exploration.ipynb`  
3. æŒ‰é †åºé‹è¡Œæ¯å€‹ cell (Shift + Enter)
4. è§€å¯Ÿæ•¸æ“šè¼‰å…¥ã€åˆ†æžå’Œè¦–è¦ºåŒ–çµæžœ

---

## ðŸ”§ **ç¬¬äºŒæ­¥ï¼šåŸ·è¡Œå…·é«”çµ„ä»¶å¯¦ä½œ**

### **A. æ•¸æ“šè™•ç†çµ„ä»¶** (`src/data_processing.py`)

**åŠŸèƒ½åŒ…å«ï¼š**
- æ•¸æ“šè¼‰å…¥å’Œåˆä½µ
- ç¼ºå¤±å€¼åˆ†æžå’Œè™•ç†
- ç•°å¸¸å€¼æª¢æ¸¬å’Œè™•ç†
- ç‰¹å¾µé¡žåž‹è­˜åˆ¥

**ä½¿ç”¨æ–¹å¼ï¼š**
```python
from src.data_processing import DataProcessor

# åˆå§‹åŒ–è™•ç†å™¨
processor = DataProcessor()

# è¼‰å…¥æ•¸æ“š
df = processor.load_data('train_transaction.csv', 'train_identity.csv')

# åŸºæœ¬é è™•ç†
df_processed = processor.basic_preprocessing(df)
```

### **B. ç‰¹å¾µå·¥ç¨‹çµ„ä»¶** (`src/feature_engineering.py`)

**åŠŸèƒ½åŒ…å«ï¼š**
- æ™‚é–“ç‰¹å¾µå‰µå»º
- äº¤æ˜“é‡‘é¡ç‰¹å¾µ
- èšåˆçµ±è¨ˆç‰¹å¾µ
- äº¤äº’ç‰¹å¾µ
- é¡žåˆ¥ç‰¹å¾µç·¨ç¢¼

**ä½¿ç”¨æ–¹å¼ï¼š**
```python
from src.feature_engineering import FeatureEngineer

# åˆå§‹åŒ–ç‰¹å¾µå·¥ç¨‹å™¨
engineer = FeatureEngineer()

# åŸ·è¡Œå®Œæ•´ç‰¹å¾µå·¥ç¨‹
df_engineered = engineer.full_feature_engineering_pipeline(df_processed)
```

### **C. æ¨¡åž‹è¨“ç·´çµ„ä»¶** (`src/modeling.py`)

**åŠŸèƒ½åŒ…å«ï¼š**
- å¤šç¨®æ©Ÿå™¨å­¸ç¿’ç®—æ³•
- æ¨¡åž‹è¨“ç·´å’Œè©•ä¼°
- ç‰¹å¾µé‡è¦æ€§åˆ†æž
- ROCæ›²ç·šæ¯”è¼ƒ

**ä½¿ç”¨æ–¹å¼ï¼š**
```python
from src.modeling import FraudDetectionModel

# åˆå§‹åŒ–æ¨¡åž‹è¨“ç·´å™¨
model_trainer = FraudDetectionModel()

# æº–å‚™æ•¸æ“š
X_train, X_test, y_train, y_test = model_trainer.prepare_data(df_engineered)

# è¨“ç·´æ‰€æœ‰æ¨¡åž‹
model_trainer.train_all_models(X_train, y_train)

# è©•ä¼°æ¨¡åž‹
for model_name in model_trainer.models.keys():
    model_trainer.evaluate_model(model_name, X_test, y_test)
```

---

## ðŸŽ¯ **ç¬¬ä¸‰æ­¥ï¼šæ¨£å¼èª¿æ•´å’Œå„ªåŒ–**

### **éµå¾ªå”ä½œæŒ‡å—åŽŸå‰‡ï¼š**

1. **Claude Code** â†’ è¤‡é›œåˆ†æžå’Œç³»çµ±æ“ä½œ
2. **Cursor IDE** â†’ å…·é«”ä»£ç¢¼ç·¨å¯«å’Œå„ªåŒ–  
3. **ä¸¦è¡Œå”ä½œ** â†’ é¿å…åŒæ™‚ç·¨è¼¯åŒä¸€æª”æ¡ˆ

### **å„ªåŒ–å»ºè­°ï¼š**

**A. æ€§èƒ½å„ªåŒ–**
```python
# ä½¿ç”¨ Dask è™•ç†å¤§æ•¸æ“š
import dask.dataframe as dd
df = dd.read_csv('train_transaction.csv')

# è¨˜æ†¶é«”å„ªåŒ–
df = df.astype({
    'TransactionAmt': 'float32',
    'TransactionDT': 'int32'
})
```

**B. ä»£ç¢¼é¢¨æ ¼å„ªåŒ–**
```python
# ä½¿ç”¨é¡žåž‹æç¤º
def process_data(df: pd.DataFrame) -> pd.DataFrame:
    return df.dropna()

# æ·»åŠ è©³ç´°è¨»é‡‹
def calculate_fraud_rate(df: pd.DataFrame) -> float:
    """
    è¨ˆç®—è©é¨™äº¤æ˜“æ¯”ä¾‹
    
    Args:
        df: åŒ…å« isFraud æ¬„ä½çš„æ•¸æ“šæ¡†
        
    Returns:
        è©é¨™äº¤æ˜“æ¯”ä¾‹ (0-1)
    """
    return df['isFraud'].mean()
```

---

## ðŸ§ª **ç¬¬å››æ­¥ï¼šæ¸¬è©¦å’Œé©—è­‰**

### **A. å–®å…ƒæ¸¬è©¦**
å‰µå»º `tests/test_data_processing.py`:
```python
import unittest
from src.data_processing import DataProcessor

class TestDataProcessor(unittest.TestCase):
    def test_load_data(self):
        processor = DataProcessor()
        # æ¸¬è©¦æ•¸æ“šè¼‰å…¥åŠŸèƒ½
        pass
```

### **B. æ•¸æ“šé©—è­‰**
```python
# æª¢æŸ¥æ•¸æ“šå“è³ª
def validate_data(df: pd.DataFrame) -> Dict[str, bool]:
    checks = {
        'no_duplicates': df.duplicated().sum() == 0,
        'target_balance': 0.01 <= df['isFraud'].mean() <= 0.1,
        'no_null_target': df['isFraud'].isnull().sum() == 0
    }
    return checks
```

### **C. æ¨¡åž‹é©—è­‰**
```python
# äº¤å‰é©—è­‰
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')
print(f"å¹³å‡ ROC-AUC: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})")
```

---

## ðŸ“Š **ç¬¬äº”æ­¥ï¼šçµæžœå±•ç¤ºå’Œå ±å‘Š**

### **A. è¦–è¦ºåŒ–çµæžœ**
```python
# æ¨¡åž‹æ¯”è¼ƒåœ–è¡¨
model_trainer.plot_roc_curves(X_test, y_test)
model_trainer.plot_feature_importance('xgboost', top_n=20)

# è©•ä¼°çµæžœæ‘˜è¦
summary = model_trainer.get_evaluation_summary()
print(summary)
```

### **B. å‰µå»ºå ±å‘Š**
åœ¨ `notebooks/03_model_evaluation.ipynb` ä¸­ï¼š
- æ¨¡åž‹æ€§èƒ½æ¯”è¼ƒ
- ç‰¹å¾µé‡è¦æ€§åˆ†æž
- æ¥­å‹™å½±éŸ¿è©•ä¼°
- çµè«–å’Œå»ºè­°

---

## ðŸ”„ **å¾ªç’°æ”¹é€²æµç¨‹**

1. **è§€å¯Ÿçµæžœ** â†’ åˆ†æžæ¨¡åž‹è¡¨ç¾
2. **è­˜åˆ¥å•é¡Œ** â†’ æ‰¾å‡ºæ”¹é€²ç©ºé–“  
3. **èª¿æ•´ç­–ç•¥** â†’ ä¿®æ”¹ç‰¹å¾µå·¥ç¨‹æˆ–æ¨¡åž‹åƒæ•¸
4. **é‡æ–°è¨“ç·´** â†’ æ‡‰ç”¨æ”¹é€²æŽªæ–½
5. **é©—è­‰æ•ˆæžœ** â†’ ç¢ºèªæ”¹é€²æ•ˆæžœ

---

## ðŸŽ¯ **å…·é«”åŸ·è¡Œæª¢æŸ¥æ¸…å–®**

### âœ… **ç«‹å³å¯åŸ·è¡Œçš„ä»»å‹™**
- [ ] é–‹å•Ÿ Jupyter Lab ä¸¦é‹è¡Œ `01_data_exploration.ipynb`
- [ ] æª¢è¦–æ•¸æ“šè¼‰å…¥çµæžœå’ŒåŸºæœ¬çµ±è¨ˆ
- [ ] åˆ†æžè©é¨™çŽ‡å’Œæ•¸æ“šåˆ†ä½ˆ
- [ ] é‹è¡Œç¼ºå¤±å€¼åˆ†æž

### ðŸ”„ **é€²éšŽå¯¦ä½œä»»å‹™**  
- [ ] å‰µå»º `02_feature_engineering.ipynb` ä¸¦å¯¦ä½œç‰¹å¾µå·¥ç¨‹
- [ ] å»ºç«‹ `03_model_training.ipynb` ä¸¦è¨“ç·´å¤šç¨®æ¨¡åž‹
- [ ] å®Œæˆ `04_model_evaluation.ipynb` é€²è¡Œæ·±åº¦è©•ä¼°
- [ ] æ’°å¯«æœ€çµ‚å ±å‘Šå’Œæ¥­å‹™å»ºè­°

---

## ðŸš€ **ç«‹å³é–‹å§‹**

**ç¾åœ¨å°±é»žæ“Šé€™å€‹é€£çµé–‹å§‹å¯¦ä½œï¼š**
```
http://localhost:8888/lab?token=ae4342b358d3b76f1648e849bd8d47abeab0ed83cd1a0151
```

**ç¬¬ä¸€å€‹ä»»å‹™ï¼š** é‹è¡Œ `notebooks/01_data_exploration.ipynb` ä¸¦è§€å¯Ÿçµæžœï¼

---
*åŸºæ–¼è¨˜æ†¶æ–‡ä»¶ç³»çµ±çš„å®Œæ•´å¯¦ä½œæŒ‡å— - é–‹å§‹æ‚¨çš„è©é¨™æª¢æ¸¬å°ˆæ¡ˆä¹‹æ—…ï¼* ðŸŽ‰ 